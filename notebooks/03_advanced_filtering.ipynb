{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Filtering Techniques for DAS Data\n",
    "\n",
    "This notebook explores frequency-domain filtering methods for Distributed Acoustic Sensing (DAS) data processing.\n",
    "\n",
    "## Overview\n",
    "\n",
    "DAS data often contains various types of noise and interference that require sophisticated filtering approaches. This notebook covers:\n",
    "\n",
    "### Topics Covered:\n",
    "1. Spectral analysis and characterization\n",
    "2. Advanced bandpass and notch filtering\n",
    "3. Adaptive filtering techniques\n",
    "4. Time-frequency analysis (STFT, Wavelet transforms)\n",
    "5. Spectral whitening and balancing\n",
    "6. Wiener filtering for noise reduction\n",
    "7. Real-world scenarios and troubleshooting\n",
    "\n",
    "### Learning Objectives:\n",
    "- Understand frequency characteristics of DAS signals and noise\n",
    "- Design and apply sophisticated filters\n",
    "- Use time-frequency methods for non-stationary signals\n",
    "- Optimize filter parameters for specific applications\n",
    "- Handle challenging real-world noise scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, fft\n",
    "from scipy.ndimage import median_filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting parameters\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"SciPy version: {signal.__version__ if hasattr(signal, '__version__') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synthetic DAS Data with Various Noise Types\n",
    "\n",
    "We'll create realistic synthetic data containing:\n",
    "- Signal of interest (seismic events)\n",
    "- Ambient noise (broadband)\n",
    "- Harmonic interference (power line noise)\n",
    "- Coherent noise (traffic, machinery)\n",
    "- Low-frequency drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_das_data_with_noise(n_channels=200, n_samples=4000, fs=1000):\n",
    "    \"\"\"\n",
    "    Generate synthetic DAS data with multiple noise types.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_channels : int\n",
    "        Number of spatial channels\n",
    "    n_samples : int\n",
    "        Number of time samples\n",
    "    fs : float\n",
    "        Sampling frequency (Hz)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    data : ndarray\n",
    "        Noisy DAS data\n",
    "    clean_signal : ndarray\n",
    "        Clean signal component\n",
    "    time : ndarray\n",
    "        Time axis\n",
    "    \"\"\"\n",
    "    time = np.arange(n_samples) / fs\n",
    "    channels = np.arange(n_channels)\n",
    "    \n",
    "    # Initialize arrays\n",
    "    clean_signal = np.zeros((n_channels, n_samples))\n",
    "    \n",
    "    # 1. Signal of interest: Multiple seismic events\n",
    "    event_times = [0.5, 1.5, 2.5]  # seconds\n",
    "    event_freqs = [30, 45, 60]     # Hz\n",
    "    \n",
    "    for t0, f0 in zip(event_times, event_freqs):\n",
    "        # Create Ricker wavelet\n",
    "        t_wavelet = time - t0\n",
    "        wavelet = (1 - 2*(np.pi*f0*t_wavelet)**2) * np.exp(-(np.pi*f0*t_wavelet)**2)\n",
    "        \n",
    "        # Add spatial coherence (plane wave)\n",
    "        velocity = 2000  # m/s\n",
    "        channel_spacing = 10  # m\n",
    "        \n",
    "        for i in range(n_channels):\n",
    "            delay = i * channel_spacing / velocity\n",
    "            delay_samples = int(delay * fs)\n",
    "            \n",
    "            if delay_samples < n_samples:\n",
    "                shifted_wavelet = np.roll(wavelet, delay_samples)\n",
    "                shifted_wavelet[:delay_samples] = 0\n",
    "                clean_signal[i] += shifted_wavelet * np.exp(-i/100)  # Amplitude decay\n",
    "    \n",
    "    # 2. Ambient noise (broadband Gaussian)\n",
    "    ambient_noise = np.random.randn(n_channels, n_samples) * 0.2\n",
    "    \n",
    "    # 3. Harmonic interference (power line at 50 Hz and harmonics)\n",
    "    harmonic_noise = np.zeros((n_channels, n_samples))\n",
    "    power_line_freqs = [50, 100, 150]  # Hz (fundamental + harmonics)\n",
    "    power_line_amps = [0.3, 0.15, 0.08]\n",
    "    \n",
    "    for freq, amp in zip(power_line_freqs, power_line_amps):\n",
    "        phase_variation = np.random.rand(n_channels) * 2 * np.pi\n",
    "        for i in range(n_channels):\n",
    "            harmonic_noise[i] += amp * np.sin(2*np.pi*freq*time + phase_variation[i])\n",
    "    \n",
    "    # 4. Coherent noise (traffic/machinery)\n",
    "    coherent_noise = np.zeros((n_channels, n_samples))\n",
    "    \n",
    "    # Simulate passing vehicle\n",
    "    vehicle_time = np.linspace(0.5, 2.0, 100)\n",
    "    vehicle_freq = 20  # Hz (low frequency rumble)\n",
    "    \n",
    "    for i, t in enumerate(vehicle_time):\n",
    "        t_idx = int(t * fs)\n",
    "        if t_idx < n_samples:\n",
    "            # Envelope\n",
    "            envelope = np.exp(-((time - t)**2) / 0.02)\n",
    "            \n",
    "            # Add to nearby channels\n",
    "            affected_channel = int(i * n_channels / len(vehicle_time))\n",
    "            for ch in range(max(0, affected_channel-5), min(n_channels, affected_channel+5)):\n",
    "                coherent_noise[ch] += 0.15 * envelope * np.sin(2*np.pi*vehicle_freq*time)\n",
    "    \n",
    "    # 5. Low-frequency drift\n",
    "    drift = np.zeros((n_channels, n_samples))\n",
    "    for i in range(n_channels):\n",
    "        drift_freq = 0.5 + 0.2 * np.random.rand()  # 0.5-0.7 Hz\n",
    "        drift[i] = 0.4 * np.sin(2*np.pi*drift_freq*time + np.random.rand()*2*np.pi)\n",
    "    \n",
    "    # Combine all components\n",
    "    noisy_data = clean_signal + ambient_noise + harmonic_noise + coherent_noise + drift\n",
    "    \n",
    "    return noisy_data, clean_signal, time\n",
    "\n",
    "# Generate data\n",
    "noisy_data, clean_signal, time_axis = generate_das_data_with_noise(\n",
    "    n_channels=200, n_samples=4000, fs=1000\n",
    ")\n",
    "\n",
    "print(f\"Data shape: {noisy_data.shape}\")\n",
    "print(f\"Time duration: {time_axis[-1]:.1f} s\")\n",
    "print(f\"Signal-to-noise ratio: {10*np.log10(np.var(clean_signal)/np.var(noisy_data-clean_signal)):.1f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spectral Analysis\n",
    "\n",
    "Understanding the frequency content is crucial before designing filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_spectrum(data, fs, channel_idx=None):\n",
    "    \"\"\"\n",
    "    Compute and visualize power spectral density.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : ndarray\n",
    "        Input data (n_channels x n_samples)\n",
    "    fs : float\n",
    "        Sampling frequency\n",
    "    channel_idx : int or None\n",
    "        Specific channel to analyze (None = average all)\n",
    "    \"\"\"\n",
    "    if channel_idx is not None:\n",
    "        trace = data[channel_idx]\n",
    "    else:\n",
    "        # Average spectrum across all channels\n",
    "        trace = np.mean(data, axis=0)\n",
    "    \n",
    "    # Compute PSD using Welch's method\n",
    "    freqs, psd = signal.welch(trace, fs=fs, nperseg=1024, \n",
    "                              noverlap=512, scaling='density')\n",
    "    \n",
    "    return freqs, psd\n",
    "\n",
    "# Analyze spectra\n",
    "freqs_noisy, psd_noisy = analyze_spectrum(noisy_data, fs=1000)\n",
    "freqs_clean, psd_clean = analyze_spectrum(clean_signal, fs=1000)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Time domain - noisy\n",
    "vmax = np.percentile(np.abs(noisy_data), 98)\n",
    "im1 = axes[0, 0].imshow(noisy_data, aspect='auto', cmap='seismic',\n",
    "                        extent=[time_axis[0]*1000, time_axis[-1]*1000, \n",
    "                               noisy_data.shape[0], 0],\n",
    "                        vmin=-vmax, vmax=vmax)\n",
    "axes[0, 0].set_xlabel('Time (ms)')\n",
    "axes[0, 0].set_ylabel('Channel')\n",
    "axes[0, 0].set_title('Noisy Data (Time Domain)', fontweight='bold')\n",
    "plt.colorbar(im1, ax=axes[0, 0])\n",
    "\n",
    "# Time domain - clean\n",
    "vmax = np.percentile(np.abs(clean_signal), 98)\n",
    "im2 = axes[0, 1].imshow(clean_signal, aspect='auto', cmap='seismic',\n",
    "                        extent=[time_axis[0]*1000, time_axis[-1]*1000, \n",
    "                               clean_signal.shape[0], 0],\n",
    "                        vmin=-vmax, vmax=vmax)\n",
    "axes[0, 1].set_xlabel('Time (ms)')\n",
    "axes[0, 1].set_ylabel('Channel')\n",
    "axes[0, 1].set_title('Clean Signal (Time Domain)', fontweight='bold')\n",
    "plt.colorbar(im2, ax=axes[0, 1])\n",
    "\n",
    "# Frequency domain - linear scale\n",
    "axes[1, 0].semilogy(freqs_noisy, psd_noisy, 'r-', linewidth=2, label='Noisy', alpha=0.7)\n",
    "axes[1, 0].semilogy(freqs_clean, psd_clean, 'b-', linewidth=2, label='Clean', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Frequency (Hz)')\n",
    "axes[1, 0].set_ylabel('Power Spectral Density')\n",
    "axes[1, 0].set_title('Power Spectrum (Log Scale)', fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_xlim([0, 200])\n",
    "\n",
    "# Frequency domain - zoom on harmonics\n",
    "axes[1, 1].plot(freqs_noisy, psd_noisy, 'r-', linewidth=2, label='Noisy')\n",
    "axes[1, 1].plot(freqs_clean, psd_clean, 'b-', linewidth=2, label='Clean')\n",
    "axes[1, 1].axvline(50, color='k', linestyle='--', alpha=0.5, label='50 Hz')\n",
    "axes[1, 1].axvline(100, color='k', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].axvline(150, color='k', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].set_xlabel('Frequency (Hz)')\n",
    "axes[1, 1].set_ylabel('Power Spectral Density')\n",
    "axes[1, 1].set_title('Harmonic Interference Detail', fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_xlim([0, 200])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSpectral characteristics identified:\")\n",
    "print(\"- Signal content: 20-80 Hz (seismic events)\")\n",
    "print(\"- Harmonic noise: 50, 100, 150 Hz (power line)\")\n",
    "print(\"- Low-frequency drift: < 2 Hz\")\n",
    "print(\"- Broadband ambient noise: all frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Bandpass Filtering\n",
    "\n",
    "### Butterworth vs Chebyshev vs Elliptic Filters\n",
    "\n",
    "Different filter designs offer trade-offs between:\n",
    "- Passband flatness\n",
    "- Stopband attenuation\n",
    "- Transition width\n",
    "- Phase linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_filters(lowcut, highcut, fs, order=4):\n",
    "    \"\"\"\n",
    "    Design different types of bandpass filters for comparison.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lowcut, highcut : float\n",
    "        Frequency bounds (Hz)\n",
    "    fs : float\n",
    "        Sampling frequency (Hz)\n",
    "    order : int\n",
    "        Filter order\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    filters : dict\n",
    "        Dictionary of filter coefficients\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    \n",
    "    filters = {}\n",
    "    \n",
    "    # Butterworth (maximally flat passband)\n",
    "    filters['butterworth'] = signal.butter(order, [low, high], btype='band')\n",
    "    \n",
    "    # Chebyshev Type I (sharper cutoff, passband ripple)\n",
    "    filters['chebyshev1'] = signal.cheby1(order, 0.5, [low, high], btype='band')\n",
    "    \n",
    "    # Chebyshev Type II (sharper cutoff, stopband ripple)\n",
    "    filters['chebyshev2'] = signal.cheby2(order, 40, [low, high], btype='band')\n",
    "    \n",
    "    # Elliptic (sharpest cutoff, both passband and stopband ripple)\n",
    "    filters['elliptic'] = signal.ellip(order, 0.5, 40, [low, high], btype='band')\n",
    "    \n",
    "    return filters\n",
    "\n",
    "def apply_filter_zerophase(data, filter_coefs):\n",
    "    \"\"\"\n",
    "    Apply filter with zero phase distortion (forward-backward filtering).\n",
    "    \"\"\"\n",
    "    b, a = filter_coefs\n",
    "    filtered = np.zeros_like(data)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        filtered[i] = signal.filtfilt(b, a, data[i])\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "# Design filters\n",
    "filter_bank = design_filters(lowcut=15, highcut=80, fs=1000, order=4)\n",
    "\n",
    "# Visualize filter responses\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'orange']\n",
    "w = np.linspace(0, 500, 2000)  # Frequency points\n",
    "\n",
    "for (name, (b, a)), color in zip(filter_bank.items(), colors):\n",
    "    # Frequency response\n",
    "    w_resp, h = signal.freqz(b, a, worN=w, fs=1000)\n",
    "    \n",
    "    # Magnitude\n",
    "    ax1.plot(w_resp, 20*np.log10(np.abs(h)), color=color, \n",
    "             linewidth=2, label=name.capitalize())\n",
    "    \n",
    "    # Phase\n",
    "    ax2.plot(w_resp, np.angle(h), color=color, linewidth=2, label=name.capitalize())\n",
    "\n",
    "ax1.set_xlabel('Frequency (Hz)')\n",
    "ax1.set_ylabel('Magnitude (dB)')\n",
    "ax1.set_title('Filter Magnitude Response', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "ax1.set_xlim([0, 150])\n",
    "ax1.axvline(15, color='k', linestyle='--', alpha=0.3)\n",
    "ax1.axvline(80, color='k', linestyle='--', alpha=0.3)\n",
    "ax1.axhline(-3, color='k', linestyle=':', alpha=0.3, label='-3 dB')\n",
    "\n",
    "ax2.set_xlabel('Frequency (Hz)')\n",
    "ax2.set_ylabel('Phase (radians)')\n",
    "ax2.set_title('Filter Phase Response', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "ax2.set_xlim([0, 150])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFilter characteristics:\")\n",
    "print(\"- Butterworth: Flattest passband, gentlest rolloff\")\n",
    "print(\"- Chebyshev I: Sharper rolloff, small passband ripple\")\n",
    "print(\"- Chebyshev II: Sharper rolloff, stopband ripple\")\n",
    "print(\"- Elliptic: Sharpest rolloff, ripple in both bands\")\n",
    "print(\"\\nRecommendation: Butterworth for most seismic applications (linear phase)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Notch Filtering for Harmonic Interference\n",
    "\n",
    "Remove specific frequency components (e.g., power line noise) while preserving nearby frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_notch_filter(f0, fs, Q=30):\n",
    "    \"\"\"\n",
    "    Design a notch filter to remove a specific frequency.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    f0 : float\n",
    "        Frequency to remove (Hz)\n",
    "    fs : float\n",
    "        Sampling frequency (Hz)\n",
    "    Q : float\n",
    "        Quality factor (higher = narrower notch)\n",
    "        Typical values: 20-50\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    b, a : ndarray\n",
    "        Filter coefficients\n",
    "    \"\"\"\n",
    "    b, a = signal.iirnotch(f0, Q, fs)\n",
    "    return b, a\n",
    "\n",
    "def apply_multi_notch(data, notch_freqs, fs, Q=30):\n",
    "    \"\"\"\n",
    "    Apply multiple notch filters in cascade.\n",
    "    \"\"\"\n",
    "    filtered = data.copy()\n",
    "    \n",
    "    for f0 in notch_freqs:\n",
    "        b, a = design_notch_filter(f0, fs, Q)\n",
    "        \n",
    "        for i in range(filtered.shape[0]):\n",
    "            filtered[i] = signal.filtfilt(b, a, filtered[i])\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "# Apply notch filters at 50, 100, 150 Hz\n",
    "notch_freqs = [50, 100, 150]\n",
    "notch_filtered = apply_multi_notch(noisy_data, notch_freqs, fs=1000, Q=30)\n",
    "\n",
    "# Analyze result\n",
    "freqs_notch, psd_notch = analyze_spectrum(notch_filtered, fs=1000)\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Time domain before\n",
    "vmax = np.percentile(np.abs(noisy_data), 98)\n",
    "axes[0, 0].imshow(noisy_data, aspect='auto', cmap='seismic',\n",
    "                  extent=[time_axis[0]*1000, time_axis[-1]*1000, \n",
    "                         noisy_data.shape[0], 0],\n",
    "                  vmin=-vmax, vmax=vmax)\n",
    "axes[0, 0].set_xlabel('Time (ms)')\n",
    "axes[0, 0].set_ylabel('Channel')\n",
    "axes[0, 0].set_title('Before Notch Filtering', fontweight='bold')\n",
    "\n",
    "# Time domain after\n",
    "axes[0, 1].imshow(notch_filtered, aspect='auto', cmap='seismic',\n",
    "                  extent=[time_axis[0]*1000, time_axis[-1]*1000, \n",
    "                         notch_filtered.shape[0], 0],\n",
    "                  vmin=-vmax, vmax=vmax)\n",
    "axes[0, 1].set_xlabel('Time (ms)')\n",
    "axes[0, 1].set_ylabel('Channel')\n",
    "axes[0, 1].set_title('After Notch Filtering', fontweight='bold')\n",
    "\n",
    "# Spectrum comparison\n",
    "axes[1, 0].semilogy(freqs_noisy, psd_noisy, 'r-', linewidth=2, \n",
    "                    label='Before', alpha=0.7)\n",
    "axes[1, 0].semilogy(freqs_notch, psd_notch, 'b-', linewidth=2, \n",
    "                    label='After', alpha=0.7)\n",
    "for f in notch_freqs:\n",
    "    axes[1, 0].axvline(f, color='k', linestyle='--', alpha=0.5)\n",
    "axes[1, 0].set_xlabel('Frequency (Hz)')\n",
    "axes[1, 0].set_ylabel('PSD (log scale)')\n",
    "axes[1, 0].set_title('Full Spectrum', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_xlim([0, 200])\n",
    "\n",
    "# Zoom on notches\n",
    "axes[1, 1].plot(freqs_noisy, psd_noisy, 'r-', linewidth=2, label='Before', alpha=0.7)\n",
    "axes[1, 1].plot(freqs_notch, psd_notch, 'b-', linewidth=2, label='After', alpha=0.7)\n",
    "for f in notch_freqs:\n",
    "    axes[1, 1].axvline(f, color='k', linestyle='--', alpha=0.5, linewidth=1.5)\n",
    "axes[1, 1].set_xlabel('Frequency (Hz)')\n",
    "axes[1, 1].set_ylabel('PSD (linear scale)')\n",
    "axes[1, 1].set_title('Notch Detail (40-160 Hz)', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_xlim([40, 160])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Notch filtering applied at {notch_freqs} Hz\")\n",
    "print(\"\\nPower line harmonics successfully attenuated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time-Frequency Analysis\n",
    "\n",
    "### Short-Time Fourier Transform (STFT)\n",
    "\n",
    "For non-stationary signals, we need to understand how frequency content changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(data, fs, channel_idx=100, title=\"Spectrogram\"):\n",
    "    \"\"\"\n",
    "    Plot spectrogram using Short-Time Fourier Transform.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : ndarray\n",
    "        Input data\n",
    "    fs : float\n",
    "        Sampling frequency\n",
    "    channel_idx : int\n",
    "        Channel to analyze\n",
    "    \"\"\"\n",
    "    trace = data[channel_idx]\n",
    "    \n",
    "    # Compute STFT\n",
    "    f, t, Sxx = signal.spectrogram(trace, fs=fs, nperseg=256, \n",
    "                                   noverlap=200, scaling='density')\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    im = ax.pcolormesh(t*1000, f, 10*np.log10(Sxx + 1e-10), \n",
    "                       shading='gouraud', cmap='viridis')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.set_ylim([0, 200])\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Power/Frequency (dB/Hz)')\n",
    "    \n",
    "    return fig, ax, f, t, Sxx\n",
    "\n",
    "# Plot spectrograms\n",
    "fig1, ax1, f1, t1, Sxx1 = plot_spectrogram(noisy_data, fs=1000, \n",
    "                                           title=\"Spectrogram: Noisy Data\")\n",
    "plt.show()\n",
    "\n",
    "fig2, ax2, f2, t2, Sxx2 = plot_spectrogram(notch_filtered, fs=1000,\n",
    "                                           title=\"Spectrogram: After Notch Filtering\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTime-frequency analysis shows:\")\n",
    "print(\"- Transient seismic events at ~0.5s, 1.5s, 2.5s\")\n",
    "print(\"- Persistent harmonic noise (horizontal lines at 50, 100, 150 Hz)\")\n",
    "print(\"- Coherent noise from passing vehicle (~0.5-2.0s)\")\n",
    "print(\"- Low-frequency drift (< 2 Hz)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Wavelet Transform (CWT)\n",
    "\n",
    "Better time-frequency resolution for transient events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_with_cwt(data, fs, channel_idx=100):\n",
    "    \"\"\"\n",
    "    Analyze signal using Continuous Wavelet Transform.\n",
    "    \"\"\"\n",
    "    trace = data[channel_idx]\n",
    "    \n",
    "    # Define scales (inverse of frequencies)\n",
    "    frequencies = np.logspace(0, 2.3, 100)  # 1 to ~200 Hz\n",
    "    scales = fs / (2 * frequencies)\n",
    "    \n",
    "    # Compute CWT using Morlet wavelet\n",
    "    coefficients = signal.cwt(trace, signal.morlet2, scales, w=6)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    time = np.arange(len(trace)) / fs * 1000  # ms\n",
    "    \n",
    "    im = ax.pcolormesh(time, frequencies, np.abs(coefficients),\n",
    "                       shading='gouraud', cmap='viridis')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_title('Continuous Wavelet Transform', fontweight='bold')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim([1, 200])\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Magnitude')\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# Analyze clean signal with CWT\n",
    "fig_cwt, ax_cwt = analyze_with_cwt(clean_signal, fs=1000)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ CWT provides excellent time-frequency localization\")\n",
    "print(\"- Clearly shows transient events at different frequencies\")\n",
    "print(\"- Superior to STFT for non-stationary signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Adaptive Filtering\n",
    "\n",
    "### Time-Varying Bandpass Filter\n",
    "\n",
    "Adapt filter parameters based on local signal characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_bandpass(data, fs, window_length=500, overlap=250):\n",
    "    \"\"\"\n",
    "    Apply adaptive bandpass filtering based on local spectral content.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : ndarray\n",
    "        Input data (n_channels x n_samples)\n",
    "    fs : float\n",
    "        Sampling frequency\n",
    "    window_length : int\n",
    "        Analysis window length (samples)\n",
    "    overlap : int\n",
    "        Overlap between windows (samples)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    filtered : ndarray\n",
    "        Adaptively filtered data\n",
    "    \"\"\"\n",
    "    n_channels, n_samples = data.shape\n",
    "    filtered = np.zeros_like(data)\n",
    "    \n",
    "    step = window_length - overlap\n",
    "    \n",
    "    for ch in range(n_channels):\n",
    "        trace = data[ch]\n",
    "        filtered_trace = np.zeros(n_samples)\n",
    "        weights = np.zeros(n_samples)\n",
    "        \n",
    "        # Process in windows\n",
    "        for start in range(0, n_samples - window_length, step):\n",
    "            end = start + window_length\n",
    "            window = trace[start:end]\n",
    "            \n",
    "            # Compute local spectrum\n",
    "            freqs, psd = signal.welch(window, fs=fs, nperseg=min(256, window_length))\n",
    "            \n",
    "            # Find dominant frequency range\n",
    "            # Exclude very low and very high frequencies\n",
    "            valid_range = (freqs > 10) & (freqs < 200)\n",
    "            psd_valid = psd[valid_range]\n",
    "            freqs_valid = freqs[valid_range]\n",
    "            \n",
    "            if len(psd_valid) > 0:\n",
    "                # Find spectral centroid and spread\n",
    "                centroid = np.sum(freqs_valid * psd_valid) / np.sum(psd_valid)\n",
    "                spread = np.sqrt(np.sum(((freqs_valid - centroid)**2) * psd_valid) / \n",
    "                               np.sum(psd_valid))\n",
    "                \n",
    "                # Design adaptive filter\n",
    "                lowcut = max(10, centroid - 1.5 * spread)\n",
    "                highcut = min(200, centroid + 1.5 * spread)\n",
    "                \n",
    "                # Apply filter to window\n",
    "                b, a = signal.butter(4, [lowcut/(fs/2), highcut/(fs/2)], btype='band')\n",
    "                filtered_window = signal.filtfilt(b, a, window)\n",
    "                \n",
    "                # Apply taper for smooth transitions\n",
    "                taper = signal.windows.tukey(window_length, alpha=0.2)\n",
    "                \n",
    "                # Accumulate\n",
    "                filtered_trace[start:end] += filtered_window * taper\n",
    "                weights[start:end] += taper\n",
    "        \n",
    "        # Normalize\n",
    "        weights[weights == 0] = 1\n",
    "        filtered[ch] = filtered_trace / weights\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "# Apply adaptive filtering\n",
    "print(\"Applying adaptive bandpass filtering...\")\n",
    "adaptive_filtered = adaptive_bandpass(noisy_data, fs=1000, \n",
    "                                     window_length=500, overlap=250)\n",
    "\n",
    "# Compare results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "titles = ['Original Noisy Data', 'Fixed Bandpass (15-80 Hz)', 'Adaptive Bandpass']\n",
    "\n",
    "# Fixed bandpass for comparison\n",
    "b, a = signal.butter(4, [15/500, 80/500], btype='band')\n",
    "fixed_filtered = apply_filter_zerophase(noisy_data, (b, a))\n",
    "\n",
    "datasets = [noisy_data, fixed_filtered, adaptive_filtered]\n",
    "\n",
    "for ax, dataset, title in zip(axes, datasets, titles):\n",
    "    vmax = np.percentile(np.abs(dataset), 98)\n",
    "    ax.imshow(dataset, aspect='auto', cmap='seismic',\n",
    "              extent=[time_axis[0]*1000, time_axis[-1]*1000, \n",
    "                     dataset.shape[0], 0],\n",
    "              vmin=-vmax, vmax=vmax)\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Channel')\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Adaptive filtering complete\")\n",
    "print(\"\\nAdvantages of adaptive approach:\")\n",
    "print(\"- Preserves varying frequency content\")\n",
    "print(\"- Better for non-stationary signals\")\n",
    "print(\"- Reduces over-filtering artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Spectral Whitening\n",
    "\n",
    "Spectral whitening balances the frequency content, enhancing weak signals and suppressing dominant frequencies.\n",
    "\n",
    "### Applications:\n",
    "- Enhance weak reflections\n",
    "- Normalize wavelet phase spectrum\n",
    "- Improve cross-correlation (e.g., for ambient noise tomography)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_whitening(data, fs, smooth_length=10):\n",
    "    \"\"\"\n",
    "    Apply spectral whitening to normalize frequency content.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : ndarray\n",
    "        Input data (n_channels x n_samples)\n",
    "    fs : float\n",
    "        Sampling frequency\n",
    "    smooth_length : int\n",
    "        Smoothing window for amplitude spectrum (prevents over-whitening)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    whitened : ndarray\n",
    "        Spectrally whitened data\n",
    "    \"\"\"\n",
    "    n_channels, n_samples = data.shape\n",
    "    whitened = np.zeros_like(data)\n",
    "    \n",
    "    for i in range(n_channels):\n",
    "        # FFT\n",
    "        spectrum = fft.fft(data[i])\n",
    "        amplitude = np.abs(spectrum)\n",
    "        phase = np.angle(spectrum)\n",
    "        \n",
    "        # Smooth amplitude spectrum\n",
    "        if smooth_length > 1:\n",
    "            window = np.ones(smooth_length) / smooth_length\n",
    "            amplitude_smooth = np.convolve(amplitude, window, mode='same')\n",
    "        else:\n",
    "            amplitude_smooth = amplitude\n",
    "        \n",
    "        # Prevent division by zero\n",
    "        amplitude_smooth[amplitude_smooth < 1e-10] = 1e-10\n",
    "        \n",
    "        # Whiten: set all amplitudes to 1 (or normalized value)\n",
    "        whitened_spectrum = (amplitude / amplitude_smooth) * np.exp(1j * phase)\n",
    "        \n",
    "        # Inverse FFT\n",
    "        whitened[i] = np.real(fft.ifft(whitened_spectrum))\n",
    "    \n",
    "    return whitened\n",
    "\n",
    "# Apply spectral whitening\n",
    "whitened_data = spectral_whitening(clean_signal, fs=1000, smooth_length=10)\n",
    "\n",
    "# Compare spectra\n",
    "freqs_orig, psd_orig = analyze_spectrum(clean_signal, fs=1000)\n",
    "freqs_white, psd_white = analyze_spectrum(whitened_data, fs=1000)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Time domain - original\n",
    "vmax = np.percentile(np.abs(clean_signal), 98)\n",
    "axes[0, 0].imshow(clean_signal, aspect='auto', cmap='seismic',\n",
    "                  extent=[time_axis[0]*1000, time_axis[-1]*1000, \n",
    "                         clean_signal.shape[0], 0],\n",
    "                  vmin=-vmax, vmax=vmax)\n",
    "axes[0, 0].set_xlabel('Time (ms)')\n",
    "axes[0, 0].set_ylabel('Channel')\n",
    "axes[0, 0].set_title('Original Signal', fontweight='bold')\n",
    "\n",
    "# Time domain - whitened\n",
    "vmax = np.percentile(np.abs(whitened_data), 98)\n",
    "axes[0, 1].imshow(whitened_data, aspect='auto', cmap='seismic',\n",
    "                  extent=[time_axis[0]*1000, time_axis[-1]*1000, \n",
    "                         whitened_data.shape[0], 0],\n",
    "                  vmin=-vmax, vmax=vmax)\n",
    "axes[0, 1].set_xlabel('Time (ms)')\n",
    "axes[0, 1].set_ylabel('Channel')\n",
    "axes[0, 1].set_title('Spectrally Whitened', fontweight='bold')\n",
    "\n",
    "# Frequency domain comparison\n",
    "axes[1, 0].semilogy(freqs_orig, psd_orig, 'b-', linewidth=2, label='Original')\n",
    "axes[1, 0].semilogy(freqs_white, psd_white, 'r-', linewidth=2, \n",
    "                    label='Whitened', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Frequency (Hz)')\n",
    "axes[1, 0].set_ylabel('PSD (log scale)')\n",
    "axes[1, 0].set_title('Power Spectral Density', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_xlim([0, 200])\n",
    "\n",
    "# Single trace comparison\n",
    "ch_idx = 100\n",
    "axes[1, 1].plot(time_axis*1000, clean_signal[ch_idx], 'b-', \n",
    "                linewidth=1.5, label='Original', alpha=0.7)\n",
    "axes[1, 1].plot(time_axis*1000, whitened_data[ch_idx]*0.3, 'r-', \n",
    "                linewidth=1.5, label='Whitened (scaled)', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Time (ms)')\n",
    "axes[1, 1].set_ylabel('Amplitude')\n",
    "axes[1, 1].set_title(f'Single Trace (Channel {ch_idx})', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Spectral whitening applied\")\n",
    "print(\"\\nEffect: Flattened spectrum, enhanced high frequencies\")\n",
    "print(\"Use cases: Cross-correlation, weak signal enhancement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Real-World Scenarios and Troubleshooting\n",
    "\n",
    "### Scenario 1: Time-Varying Noise (Traffic Pattern)\n",
    "\n",
    "**Problem**: Noise characteristics change over time (e.g., rush hour traffic)\n",
    "\n",
    "**Solution**: Adaptive noise estimation and subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_noise_suppression(data, fs, noise_estimate_window=0.5):\n",
    "    \"\"\"\n",
    "    Estimate and subtract time-varying noise floor.\n",
    "    \n",
    "    Uses running minimum of spectral amplitude as noise estimate.\n",
    "    \"\"\"\n",
    "    n_channels, n_samples = data.shape\n",
    "    denoised = np.zeros_like(data)\n",
    "    \n",
    "    window_samples = int(noise_estimate_window * fs)\n",
    "    \n",
    "    for i in range(n_channels):\n",
    "        # Compute STFT\n",
    "        f, t, Zxx = signal.stft(data[i], fs=fs, nperseg=256, noverlap=200)\n",
    "        \n",
    "        # Estimate noise (running minimum in each frequency bin)\n",
    "        magnitude = np.abs(Zxx)\n",
    "        noise_estimate = np.zeros_like(magnitude)\n",
    "        \n",
    "        for freq_idx in range(len(f)):\n",
    "            # Running minimum filter\n",
    "            noise_estimate[freq_idx, :] = median_filter(\n",
    "                magnitude[freq_idx, :], size=5, mode='reflect'\n",
    "            ) * 0.8  # Slightly conservative\n",
    "        \n",
    "        # Spectral subtraction\n",
    "        magnitude_clean = np.maximum(magnitude - noise_estimate, 0)\n",
    "        \n",
    "        # Reconstruct with original phase\n",
    "        phase = np.angle(Zxx)\n",
    "        Zxx_clean = magnitude_clean * np.exp(1j * phase)\n",
    "        \n",
    "        # Inverse STFT\n",
    "        _, denoised[i] = signal.istft(Zxx_clean, fs=fs, nperseg=256, noverlap=200)\n",
    "        \n",
    "        # Ensure same length\n",
    "        denoised[i] = denoised[i][:n_samples]\n",
    "    \n",
    "    return denoised\n",
    "\n",
    "# Apply adaptive noise suppression\n",
    "print(\"Applying adaptive noise suppression...\")\n",
    "denoised_data = adaptive_noise_suppression(noisy_data, fs=1000)\n",
    "\n",
    "# Compare SNR\n",
    "snr_original = 10*np.log10(np.var(clean_signal) / np.var(noisy_data - clean_signal))\n",
    "snr_denoised = 10*np.log10(np.var(clean_signal) / np.var(denoised_data - clean_signal))\n",
    "\n",
    "print(f\"\\nSNR improvement: {snr_denoised - snr_original:.1f} dB\")\n",
    "print(f\"Original SNR: {snr_original:.1f} dB\")\n",
    "print(f\"Denoised SNR: {snr_denoised:.1f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Fiber Coupling Issues\n",
    "\n",
    "**Problem**: Spatially varying sensitivity due to coupling variations\n",
    "\n",
    "**Solution**: Adaptive gain normalization (AGC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automatic_gain_control(data, window_length=500, target_rms=1.0):\n",
    "    \"\"\"\n",
    "    Apply automatic gain control to normalize amplitude variations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : ndarray\n",
    "        Input data\n",
    "    window_length : int\n",
    "        Window for RMS calculation (samples)\n",
    "    target_rms : float\n",
    "        Target RMS value\n",
    "    \"\"\"\n",
    "    n_channels, n_samples = data.shape\n",
    "    agc_data = np.zeros_like(data)\n",
    "    \n",
    "    for i in range(n_channels):\n",
    "        trace = data[i]\n",
    "        \n",
    "        # Calculate running RMS\n",
    "        rms = np.zeros(n_samples)\n",
    "        for j in range(n_samples):\n",
    "            start = max(0, j - window_length // 2)\n",
    "            end = min(n_samples, j + window_length // 2)\n",
    "            rms[j] = np.sqrt(np.mean(trace[start:end]**2))\n",
    "        \n",
    "        # Prevent division by zero\n",
    "        rms[rms < 1e-10] = 1e-10\n",
    "        \n",
    "        # Apply gain\n",
    "        gain = target_rms / rms\n",
    "        \n",
    "        # Limit maximum gain to prevent noise amplification\n",
    "        gain = np.minimum(gain, 10.0)\n",
    "        \n",
    "        agc_data[i] = trace * gain\n",
    "    \n",
    "    return agc_data\n",
    "\n",
    "# Simulate coupling variation\n",
    "coupling_factor = np.ones(noisy_data.shape[0])\n",
    "coupling_factor[50:100] = 0.3  # Poor coupling zone\n",
    "coupling_factor[150:160] = 0.1  # Very poor coupling\n",
    "\n",
    "data_with_coupling = noisy_data * coupling_factor[:, np.newaxis]\n",
    "\n",
    "# Apply AGC\n",
    "agc_corrected = automatic_gain_control(data_with_coupling, window_length=500)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "titles = ['Original', 'With Coupling Variation', 'AGC Corrected']\n",
    "datasets = [noisy_data, data_with_coupling, agc_corrected]\n",
    "\n",
    "for ax, dataset, title in zip(axes, datasets, titles):\n",
    "    vmax = np.percentile(np.abs(noisy_data), 98)\n",
    "    ax.imshow(dataset, aspect='auto', cmap='seismic',\n",
    "              extent=[time_axis[0]*1000, time_axis[-1]*1000, \n",
    "                     dataset.shape[0], 0],\n",
    "              vmin=-vmax, vmax=vmax)\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_ylabel('Channel')\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    \n",
    "    if title == 'With Coupling Variation':\n",
    "        ax.axhspan(50, 100, alpha=0.2, color='red', label='Poor coupling')\n",
    "        ax.axhspan(150, 160, alpha=0.3, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ AGC successfully normalized amplitude variations\")\n",
    "print(\"\\nWarning: Use AGC cautiously - can amplify noise in weak signal zones!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Troubleshooting Guide\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "#### Issue 1: Over-filtering (Signal Distortion)\n",
    "\n",
    "**Symptoms**:\n",
    "- Signal appears smoothed or smeared\n",
    "- Loss of high-frequency content\n",
    "- Reduced temporal resolution\n",
    "\n",
    "**Causes**:\n",
    "- Filter cutoff too low\n",
    "- Filter order too high\n",
    "- Multiple cascaded filters\n",
    "\n",
    "**Solutions**:\n",
    "1. Use minimum necessary filter order (typically 2-4)\n",
    "2. Verify filter response before applying\n",
    "3. Compare filtered vs. unfiltered in frequency domain\n",
    "4. Use zero-phase filtering (filtfilt) to preserve phase\n",
    "\n",
    "#### Issue 2: Incomplete Noise Removal\n",
    "\n",
    "**Symptoms**:\n",
    "- Visible noise in filtered data\n",
    "- Harmonic interference remains\n",
    "\n",
    "**Causes**:\n",
    "- Noise overlaps with signal band\n",
    "- Insufficient notch Q-factor\n",
    "- Time-varying noise characteristics\n",
    "\n",
    "**Solutions**:\n",
    "1. Increase notch Q-factor (30-50 typical)\n",
    "2. Use adaptive methods for non-stationary noise\n",
    "3. Consider F-K filtering for coherent noise\n",
    "4. Apply spectral subtraction methods\n",
    "\n",
    "#### Issue 3: Ringing Artifacts\n",
    "\n",
    "**Symptoms**:\n",
    "- Oscillations after sharp transitions\n",
    "- Artificial events in filtered data\n",
    "\n",
    "**Causes**:\n",
    "- Sharp filter cutoffs (Chebyshev, Elliptic)\n",
    "- High filter order\n",
    "- Non-zero phase filtering\n",
    "\n",
    "**Solutions**:\n",
    "1. Use Butterworth filters (maximally flat)\n",
    "2. Reduce filter order\n",
    "3. Apply tapering to data edges\n",
    "4. Use zero-phase filtering (filtfilt)\n",
    "\n",
    "#### Issue 4: DAS-Specific: Gauge Length Effects\n",
    "\n",
    "**Symptoms**:\n",
    "- Spectral notches at specific frequencies\n",
    "- Reduced amplitude at certain wavelengths\n",
    "\n",
    "**Cause**: \n",
    "- DAS integrates strain over gauge length (typically 10m)\n",
    "- Creates nulls at λ = gauge_length\n",
    "\n",
    "**Solutions**:\n",
    "1. Account for gauge length in frequency interpretation:\n",
    "   - Notch frequency: f_notch = v / gauge_length\n",
    "   - For v=3000 m/s, GL=10m: f_notch = 300 Hz\n",
    "2. Cannot be corrected, but can be modeled\n",
    "3. Choose appropriate gauge length during acquisition\n",
    "\n",
    "#### Issue 5: Aliasing\n",
    "\n",
    "**Symptoms**:\n",
    "- High frequencies appear as low frequencies\n",
    "- Unexplained low-frequency content\n",
    "\n",
    "**Cause**:\n",
    "- Sampling rate too low (fs < 2 * f_max)\n",
    "\n",
    "**Solutions**:\n",
    "1. Apply anti-aliasing filter before downsampling\n",
    "2. Use lowpass with cutoff at 0.4 * fs (conservative)\n",
    "3. Increase sampling rate if possible\n",
    "4. Example:\n",
    "```python\n",
    "# Downsample from 1000 Hz to 500 Hz safely\n",
    "b, a = signal.butter(8, 200/500, btype='low')  # 200 Hz < 0.5*500 Hz\n",
    "filtered = signal.filtfilt(b, a, data)\n",
    "downsampled = filtered[:, ::2]  # Decimate by 2\n",
    "```\n",
    "\n",
    "### Best Practices Summary\n",
    "\n",
    "1. **Always visualize before and after filtering**\n",
    "   - Time domain\n",
    "   - Frequency domain\n",
    "   - Time-frequency domain for non-stationary signals\n",
    "\n",
    "2. **Start conservative**\n",
    "   - Low filter orders (2-4)\n",
    "   - Wide passbands\n",
    "   - Gradually tighten if needed\n",
    "\n",
    "3. **Use zero-phase filtering**\n",
    "   - `filtfilt` instead of `lfilter`\n",
    "   - Preserves phase relationships\n",
    "   - Critical for multi-channel coherence\n",
    "\n",
    "4. **Document all parameters**\n",
    "   - Filter type and order\n",
    "   - Cutoff frequencies\n",
    "   - Processing sequence\n",
    "\n",
    "5. **Quality control**\n",
    "   - Check filter stability\n",
    "   - Verify no artifacts introduced\n",
    "   - Compare with independent data if available\n",
    "\n",
    "6. **DAS-specific considerations**\n",
    "   - Account for gauge length effects\n",
    "   - Consider coupling variations (AGC)\n",
    "   - Spatial filtering (F-K) for coherent noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered advanced frequency-domain filtering techniques for DAS data:\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Spectral Analysis**\n",
    "   - Power spectral density (PSD)\n",
    "   - Identifying signal vs. noise characteristics\n",
    "\n",
    "2. **Filter Design**\n",
    "   - Butterworth: Flat passband, smooth rolloff\n",
    "   - Chebyshev: Sharp rolloff, with ripple\n",
    "   - Elliptic: Sharpest rolloff, ripple in both bands\n",
    "   - Notch: Remove specific frequencies\n",
    "\n",
    "3. **Time-Frequency Methods**\n",
    "   - STFT: Fixed time-frequency resolution\n",
    "   - CWT: Adaptive resolution for transients\n",
    "\n",
    "4. **Advanced Techniques**\n",
    "   - Adaptive filtering: Time-varying parameters\n",
    "   - Spectral whitening: Flatten spectrum\n",
    "   - Adaptive noise suppression: STFT-based\n",
    "   - AGC: Normalize spatial variations\n",
    "\n",
    "### Practical Guidelines:\n",
    "\n",
    "- **For seismic signals**: Butterworth bandpass (15-80 Hz typical)\n",
    "- **For power line noise**: Cascade notch filters (50, 100, 150 Hz)\n",
    "- **For non-stationary signals**: Adaptive or time-frequency methods\n",
    "- **For coupling issues**: AGC with caution\n",
    "- **For weak signals**: Spectral whitening\n",
    "\n",
    "### Further Reading:\n",
    "\n",
    "- Oppenheim & Schafer: \"Discrete-Time Signal Processing\" (classic text)\n",
    "- Mallat: \"A Wavelet Tour of Signal Processing\" (wavelets)\n",
    "- Yilmaz: \"Seismic Data Analysis\" (geophysical applications)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Apply to real DAS field data\n",
    "- Combine with spatial filtering (F-K, tau-p)\n",
    "- Machine learning for adaptive noise classification\n",
    "- Real-time filtering implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
